{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2) Perform all linear algebra operation with Tensorflow.",
   "id": "a1c30020c7f6f0ca"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-05T09:32:55.602146Z",
     "start_time": "2026-01-05T09:32:52.051973Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "A=tf.constant([[4.7,9.5],\n",
    "              [3.3,6]])\n",
    "B=tf.constant([[5.5,7.8],\n",
    "              [3.9,4.7]])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amees\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:32:55.624365Z",
     "start_time": "2026-01-05T09:32:55.610152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tf.add(A,B))\n",
    "print(tf.subtract(A,B))\n",
    "print(tf.multiply(A,B))"
   ],
   "id": "81b16d18b2833d31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10.2 17.3]\n",
      " [ 7.2 10.7]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.8000002   1.6999998 ]\n",
      " [-0.60000014  1.3000002 ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[25.849998 74.1     ]\n",
      " [12.87     28.199999]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:32:55.660370Z",
     "start_time": "2026-01-05T09:32:55.639371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tf.matmul(A,B))\n",
    "print(tf.tensordot(A,B,1))"
   ],
   "id": "73e6fdec2f2a2125",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[62.899998 81.31    ]\n",
      " [41.550003 53.94    ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[62.899998 81.31    ]\n",
      " [41.550003 53.94    ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:32:55.681955Z",
     "start_time": "2026-01-05T09:32:55.666880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tf.transpose(A))\n",
    "print(tf.linalg.det(A))\n",
    "print(tf.linalg.inv(A))"
   ],
   "id": "7bd0f2b3c9aec73c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.7 3.3]\n",
      " [9.5 6. ]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(-3.150002, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-1.9047606  3.0158708]\n",
      " [ 1.0476184 -1.4920624]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:32:55.706971Z",
     "start_time": "2026-01-05T09:32:55.693970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=tf.constant([[5.3],\n",
    "               [8.4]])\n",
    "print(tf.linalg.solve(A,x))\n",
    "print(tf.norm(x,ord=2))"
   ],
   "id": "77b390a402298802",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[15.238083]\n",
      " [-6.980946]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(9.93227, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:32:55.729024Z",
     "start_time": "2026-01-05T09:32:55.718513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(tf.linalg.eigh(A))\n",
    "print(tf.linalg.svd(A,full_matrices=False))"
   ],
   "id": "cdd0b46e13d77f91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.9865935, 8.713404 ], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[-0.77241707, -0.6351155 ],\n",
      "       [ 0.6351155 , -0.77241707]], dtype=float32)>)\n",
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([12.616167  ,  0.24968004], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[ 0.84004843, -0.54251146],\n",
      "       [ 0.54251146,  0.84004843]], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[ 0.45485407,  0.890566  ],\n",
      "       [ 0.890566  , -0.45485407]], dtype=float32)>)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3) Write a program to implement AND OR gates using Perceptron.",
   "id": "e83689e9cdc7fdbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:33:50.666133Z",
     "start_time": "2026-01-05T09:33:50.343246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Inputs: [0,0], [0,1], [1,0], [1,1]\n",
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "\n",
    "# Targets for AND Gate\n",
    "y_and = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)\n",
    "\n",
    "# Targets for OR Gate\n",
    "y_or = torch.tensor([[0], [1], [1], [1]], dtype=torch.float32)\n",
    "\n",
    "# 2. Define the Perceptron Model\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.linear(x))\n",
    "\n",
    "def train_gate(model, X, y, gate_name, epochs=1000):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    print(f\"\\n--- Training {gate_name} Gate ---\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 200 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    return model\n",
    "model_and = Perceptron()\n",
    "train_gate(model_and, X, y_and, \"AND\")\n",
    "\n",
    "print(\"\\nAND Gate Predictions:\")\n",
    "with torch.no_grad():\n",
    "    predictions = model_and(X)\n",
    "    predicted_classes = predictions.round()\n",
    "    for i in range(len(X)):\n",
    "        print(f\"Input: {X[i].numpy()} -> Prediction: {predicted_classes[i].item()}\")\n",
    "\n",
    "model_or = Perceptron()\n",
    "train_gate(model_or, X, y_or, \"OR\")\n",
    "\n",
    "print(\"\\nTesting OR Gate Predictions:\")\n",
    "with torch.no_grad():\n",
    "    predictions = model_or(X)\n",
    "    predicted_classes = predictions.round()\n",
    "    for i in range(len(X)):\n",
    "        print(f\"Input: {X[i].numpy()} -> Prediction: {predicted_classes[i].item()}\")"
   ],
   "id": "41a1451bd9445dcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training AND Gate ---\n",
      "Epoch [200/1000], Loss: 0.4071\n",
      "Epoch [400/1000], Loss: 0.2793\n",
      "Epoch [600/1000], Loss: 0.2156\n",
      "Epoch [800/1000], Loss: 0.1762\n",
      "Epoch [1000/1000], Loss: 0.1491\n",
      "\n",
      "AND Gate Predictions:\n",
      "Input: [0. 0.] -> Prediction: 0.0\n",
      "Input: [0. 1.] -> Prediction: 0.0\n",
      "Input: [1. 0.] -> Prediction: 0.0\n",
      "Input: [1. 1.] -> Prediction: 1.0\n",
      "\n",
      "--- Training OR Gate ---\n",
      "Epoch [200/1000], Loss: 0.2826\n",
      "Epoch [400/1000], Loss: 0.1901\n",
      "Epoch [600/1000], Loss: 0.1414\n",
      "Epoch [800/1000], Loss: 0.1118\n",
      "Epoch [1000/1000], Loss: 0.0920\n",
      "\n",
      "Testing OR Gate Predictions:\n",
      "Input: [0. 0.] -> Prediction: 0.0\n",
      "Input: [0. 1.] -> Prediction: 1.0\n",
      "Input: [1. 0.] -> Prediction: 1.0\n",
      "Input: [1. 1.] -> Prediction: 1.0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:44:22.403471Z",
     "start_time": "2026-01-05T09:44:21.356347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "class XORModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XORModel, self).__init__()\n",
    "        # We need at least 2 hidden neurons to solve XOR\n",
    "        self.hidden = nn.Linear(2, 2)\n",
    "        self.activation_hidden = nn.Sigmoid()\n",
    "        self.output = nn.Linear(2, 1)\n",
    "        self.activation_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through hidden layer\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation_hidden(x)\n",
    "\n",
    "        # Pass through output layer\n",
    "        x = self.output(x)\n",
    "        x = self.activation_output(x)\n",
    "        return x\n",
    "\n",
    "model = XORModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "epochs = 3000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "print(\"/nPredictions\")\n",
    "with torch.no_grad():\n",
    "    predictions = model(X)\n",
    "    predicted_classes = predictions.round()\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        input_val = X[i].numpy()\n",
    "        pred = predicted_classes[i].item()\n",
    "        target = y[i].item()\n",
    "        print(f\"Input: {input_val} | Target: {target} | Prediction: {pred}\")"
   ],
   "id": "1faa0a9f71314c77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/3000], Loss: 0.0027\n",
      "Epoch [1000/3000], Loss: 0.0009\n",
      "Epoch [1500/3000], Loss: 0.0004\n",
      "Epoch [2000/3000], Loss: 0.0003\n",
      "Epoch [2500/3000], Loss: 0.0002\n",
      "Epoch [3000/3000], Loss: 0.0001\n",
      "/nPredictions\n",
      "Input: [0. 0.] | Target: 0.0 | Prediction: 0.0\n",
      "Input: [0. 1.] | Target: 1.0 | Prediction: 1.0\n",
      "Input: [1. 0.] | Target: 1.0 | Prediction: 1.0\n",
      "Input: [1. 1.] | Target: 0.0 | Prediction: 0.0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T09:59:46.787372Z",
     "start_time": "2026-01-05T09:59:45.991353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "true_equation = lambda x: 2 * x[:, 0] + 3 * x[:, 1] + 5\n",
    "\n",
    "def generate_data(num_samples):\n",
    "    X = torch.rand(num_samples, 2) * 10\n",
    "    y = true_equation(X)\n",
    "    y = y.view(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "torch.manual_seed(42)\n",
    "X_train, y_train = generate_data(100)\n",
    "X_val, y_val = generate_data(20)\n",
    "\n",
    "print(f\"Target Equation: y = 2*x1 + 3*x2 + 5\")\n",
    "\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        # Input (2) -> Hidden (2)\n",
    "        self.hidden = nn.Linear(2, 2)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        # Hidden (2) -> Output (1)\n",
    "        self.output = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = RegressionNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "\n",
    "print(\"\\nTraining:\")\n",
    "epochs = 2000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    predictions = model(X_train)\n",
    "    loss = criterion(predictions, y_train)\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}] | Train Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X_val)\n",
    "    val_loss = criterion(val_predictions, y_val)\n",
    "\n",
    "    print(f\"Validation MSE Loss: {val_loss.item():.4f}\")\n",
    "    print(\"\\nFirst 5 validation predictions:\")\n",
    "    print(f\"{'Input (x1, x2)':<20} | {'Predicted':<12} | {'Actual (y)':<12} | {'Diff':<10}\")\n",
    "    for i in range(5):\n",
    "        x_vals = f\"[{X_val[i][0]:.1f}, {X_val[i][1]:.1f}]\"\n",
    "        pred = val_predictions[i].item()\n",
    "        actual = y_val[i].item()\n",
    "        diff = abs(pred - actual)\n",
    "\n",
    "        print(f\"{x_vals:<20} | {pred:<12.4f} | {actual:<12.4f} | {diff:<10.4f}\")"
   ],
   "id": "15e6879f6201e253",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Equation: y = 2*x1 + 3*x2 + 5\n",
      "\n",
      "Training:\n",
      "Epoch [500/2000] | Train Loss: 11.5819\n",
      "Epoch [1000/2000] | Train Loss: 1.9583\n",
      "Epoch [1500/2000] | Train Loss: 1.1673\n",
      "Epoch [2000/2000] | Train Loss: 0.9265\n",
      "\n",
      "Validation:\n",
      "Validation MSE Loss: 3.0367\n",
      "\n",
      "First 5 validation predictions:\n",
      "Input (x1, x2)       | Predicted    | Actual (y)   | Diff      \n",
      "[0.5, 3.2]           | 15.2728      | 15.3819      | 0.1091    \n",
      "[9.2, 6.9]           | 44.5073      | 44.2646      | 0.2427    \n",
      "[4.8, 2.0]           | 19.8704      | 20.4590      | 0.5886    \n",
      "[1.9, 0.5]           | 13.1746      | 10.4454      | 2.7291    \n",
      "[3.4, 6.7]           | 31.6113      | 31.8059      | 0.1946    \n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
